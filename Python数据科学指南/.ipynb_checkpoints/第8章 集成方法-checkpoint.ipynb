{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章 集成方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一章中，我们将探讨一下主题：\n",
    "- 理解集成——挂袋法\n",
    "- 理解集成——提升法\n",
    "- 理解集成——梯度提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章主要内容将覆盖集成方法。  \n",
    "\n",
    "基本的思路是拥有大量的模型，每一个都在训练集上产生差别不大的结果，一些模型相较其他的在某些方面的数据效果会更好一些。可以相信，最后从多个模型得到的输出结果肯定比仅从一个模型获得的结果要好。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 理解集成——挂袋法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定数据自举 $m$ 次，这样就有 $m$ 个模型，也就有 $m$ 个 $y$，最后的预测值计算公式如下：\n",
    "$$Y_{final(x)} = \\frac{1}{m}\\sum_{i=1}^my_m(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机化是用来在建模过程中引入变化的另一种技术，一个例子就是在集成的每个模型里随机选择属性的子集，这样，不同模型使用不同的属性集合。这种技术被称为随机子空间方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2 操作方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Make a sample classification dataset\n",
    "    Returns : Independent variable y, dependent variable x\n",
    "    \"\"\"\n",
    "    no_features = 30\n",
    "    redundant_features = int(0.1 * no_features)\n",
    "    informative_features = int(0.6 * no_features)\n",
    "    repeated_features = int(0.1 * no_features)\n",
    "    print(no_features, redundant_features, informative_features, repeated_features)\n",
    "    x, y = make_classification(n_samples=500,n_features=no_features,flip_y=0.03,n_informative=informative_features,\\\n",
    "                               n_redundant=redundant_features,n_repeated=repeated_features,random_state=7)\n",
    "    return x,y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_single_model(x,y):\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(x,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bagging_model(x,y):\n",
    "    bagging = BaggingClassifier(KNeighborsClassifier(),n_estimators=100,random_state=9,max_samples=1.0,max_features=0.7,bootstrap=True,\\\n",
    "                               bootstrap_features=True)\n",
    "    bagging.fit(x,y)\n",
    "    return bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_model(model):\n",
    "    print(\"\\n Sampled attributes in top 10 estimators\\n\")\n",
    "    for i,feature_set in enumerate(model.estimators_features_[0:10]):\n",
    "        print(\"estimator %d\"%(i+1), feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 3 18 3\n",
      "\n",
      " Single Model Accuracy on training data\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.87      0.88       181\n",
      "          1       0.87      0.88      0.87       169\n",
      "\n",
      "avg / total       0.87      0.87      0.87       350\n",
      "\n",
      "\n",
      " Bagging Model Accuracy on training data\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       181\n",
      "          1       0.96      0.92      0.94       169\n",
      "\n",
      "avg / total       0.95      0.95      0.95       350\n",
      "\n",
      "\n",
      " Sampled attributes in top 10 estimators\n",
      "\n",
      "estimator 1 [25 20 10  6 17 18 11 17  9 14  3 10 10 23 22 18 17 11 21 20  1]\n",
      "estimator 2 [14  3 27 28 20 20 27 25  0 21  1 12 20 21 29  1  0 28 16  4  9]\n",
      "estimator 3 [29  5 23 19  2 16 21  4 13 27  1 15 24  5 14  1  4 25 22 26 29]\n",
      "estimator 4 [23 10 16  7 22 11  0 14 14 17  8 17 27 12 13 23  8  7 27  0 27]\n",
      "estimator 5 [ 3  0 26 13 23  7 27 15 18 11 26 18 26  3 22  6 11 21  6 12 19]\n",
      "estimator 6 [16  5 24 19 21  2  2 22 12 21 14 28  5 29  9 19 24 14 21  8 11]\n",
      "estimator 7 [ 7 23  2 17 22  2 12 14 25  5  7 10 25  5 17 16  9  0  9  9 15]\n",
      "estimator 8 [16 10  7  8  8 18  6  3 12 29 13 17 20  9  2 25  6 28 15  0 16]\n",
      "estimator 9 [22 29  2  5  6 11 18  4 19 27 17 28 20 15 21 26 14  5 28 15 21]\n",
      "estimator 10 [29 22 17 10 16 10 27  8  2 18 26  1  3  2  1 17  2 12 10 22 26]\n",
      "\n",
      " Single Model Accuracy on Dev data\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.84      0.83        51\n",
      "          1       0.85      0.83      0.84        54\n",
      "\n",
      "avg / total       0.84      0.84      0.84       105\n",
      "\n",
      "\n",
      " Bagging Model Accuracy on Dev data\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.86        51\n",
      "          1       0.88      0.83      0.86        54\n",
      "\n",
      "avg / total       0.86      0.86      0.86       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = get_data()\n",
    "\n",
    "# 将数据划分为训练集、dev集和测试集\n",
    "x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size=0.3,random_state=9)\n",
    "x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)\n",
    "\n",
    "# 构建单个模型\n",
    "model = build_single_model(x_train,y_train)\n",
    "predicted_y = model.predict(x_train)\n",
    "print(\"\\n Single Model Accuracy on training data\\n\")\n",
    "print(classification_report(y_train,predicted_y))\n",
    "\n",
    "# 构建多个模型\n",
    "bagging = build_bagging_model(x_train,y_train)\n",
    "predicted_y = bagging.predict(x_train)\n",
    "print(\"\\n Bagging Model Accuracy on training data\\n\")\n",
    "print(classification_report(y_train,predicted_y))\n",
    "view_model(bagging)\n",
    "\n",
    "# 查看dev集上运行的情况\n",
    "print(\"\\n Single Model Accuracy on Dev data\\n\")\n",
    "predicted_y = model.predict(x_dev)\n",
    "print(classification_report(y_dev,predicted_y))\n",
    "\n",
    "print(\"\\n Bagging Model Accuracy on Dev data\\n\")\n",
    "predicted_y = bagging.predict(x_dev)\n",
    "print(classification_report(y_dev,predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.3 工作原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_features = 30\n",
    "redundant_features = int(0.1 * no_features)\n",
    "informative_features = int(0.6 * no_features)\n",
    "repeated_features = int(0.1 * no_features)\n",
    "\n",
    "# n_samples是所需的实例数量\n",
    "# n_features是每个实例需要的属性数量\n",
    "# flip_y要求随机互换实例的%3，这是为了在数据中产生一些噪音。\n",
    "# n_informative指定了从30个特征中选择具有足够的信息量来进行分类的特征个数\n",
    "# n_redundant是关于冗余参数的，它们产生了高信息量特征的线性组合以构成特征之间的关联。\n",
    "# n_repeated重复特征是从高信息量特征和冗余特征中随机选择的副本。\n",
    "x, y = make_classification(n_samples=500,n_features=no_features,flip_y=0.03,n_informative=informative_features,\\\n",
    "                               n_redundant=redundant_features,n_repeated=repeated_features,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.4 更多内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.5 参考资料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
