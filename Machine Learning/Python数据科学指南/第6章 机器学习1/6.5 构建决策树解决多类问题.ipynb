{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 构建决策树解决多类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def prob(data, element):\n",
    "    \"\"\"\n",
    "    Calculates the percentage count of a given element\n",
    "    Given a list and an element, returns the elements percentage count\n",
    "    \"\"\"\n",
    "    element_count = 0\n",
    "    \n",
    "    # 测试条件以检查输入是否正确\n",
    "    if len(data)==0 or element==None or not isinstance(element, (int,float)):\n",
    "        return None\n",
    "    element_count = data.count(element)\n",
    "    return element_count / len(data)\n",
    "\n",
    "def entropy(data):\n",
    "    \"\"\"\n",
    "    Calculate entropy\n",
    "    \"\"\"\n",
    "    entropy = 0.0\n",
    "    \n",
    "    if len(data)==0:\n",
    "        return None\n",
    "    if len(data)==1:\n",
    "        return 0\n",
    "    try:\n",
    "        for element in data:\n",
    "            p = prob(data, element)\n",
    "            entropy += -1*p*math.log(p,2)\n",
    "    except ValueError as e:\n",
    "        print(e.message)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.2 操作方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 100.00%\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "=================\n",
      "array([[40,  0,  0],\n",
      "       [ 0, 40,  0],\n",
      "       [ 0,  0, 40]])\n",
      "None\n",
      "\n",
      "Classification Report\n",
      "=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        40\n",
      " versicolor       1.00      1.00      1.00        40\n",
      "  virginica       1.00      1.00      1.00        40\n",
      "\n",
      "avg / total       1.00      1.00      1.00       120\n",
      "\n",
      "Model accuracy = 96.67%\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "=================\n",
      "array([[10,  0,  0],\n",
      "       [ 0,  9,  1],\n",
      "       [ 0,  0, 10]])\n",
      "None\n",
      "\n",
      "Classification Report\n",
      "=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        10\n",
      " versicolor       1.00      0.90      0.95        10\n",
      "  virginica       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import pprint\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get Iris data\n",
    "    \"\"\"\n",
    "    data = load_iris()\n",
    "    x = data['data']\n",
    "    y = data['target']\n",
    "    label_names = data['target_names']\n",
    "    return x,y,label_names.tolist()\n",
    "\n",
    "def get_train_test(x,y):\n",
    "    \"\"\"\n",
    "    Perpare a stratified train and test split\n",
    "    \"\"\"\n",
    "    train_size = 0.8\n",
    "    test_size = 1 - train_size\n",
    "    input_dataset = np.column_stack([x,y])\n",
    "    stratified_split = StratifiedShuffleSplit(input_dataset[:,-1],test_size=test_size,n_iter=1,random_state=77)\n",
    "    \n",
    "    for train_indx,test_indx in stratified_split:\n",
    "        train_x = input_dataset[train_indx,:-1]\n",
    "        train_y = input_dataset[train_indx,-1]\n",
    "        test_x = input_dataset[test_indx,:-1]\n",
    "        test_y = input_dataset[test_indx,-1]\n",
    "    \n",
    "    return train_x,train_y,test_x,test_y\n",
    "\n",
    "def build_model(x,y):\n",
    "    \"\"\"\n",
    "    Fit the model for the given attribute class label pairs\n",
    "    \"\"\"\n",
    "    model = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    model = model.fit(x,y)\n",
    "    return model\n",
    "\n",
    "def test_model(x,y,model,label_names):\n",
    "    \"\"\"\n",
    "    Inspect the model for accuracy\n",
    "    \"\"\"\n",
    "    y_predicted = model.predict(x)\n",
    "    print(\"Model accuracy = %0.2f\"%(accuracy_score(y,y_predicted) * 100) + \"%\\n\")\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(\"=================\")\n",
    "    print(pprint.pprint(confusion_matrix(y,y_predicted)))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(\"=================\")\n",
    "    \n",
    "    print(classification_report(y,y_predicted,target_names=label_names))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    x,y,label_names = get_data()\n",
    "    # 将数据分割为训练集和测试集\n",
    "    train_x,train_y,test_x,test_y = get_train_test(x,y)\n",
    "    # 建模\n",
    "    model = build_model(train_x,train_y)\n",
    "    # 在训练集上评估模型\n",
    "    test_model(train_x,train_y,model,label_names)\n",
    "    # 在测试集上评估模型\n",
    "    test_model(test_x,test_y,model,label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.3 工作原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\Documents\\\\Python\\\\MyGit\\\\Machine Learning\\\\Python数据科学指南\\\\第6章 机器学习1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.4 更多内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_names():\n",
    "    data = load_iris()\n",
    "    return data['feature_names']\n",
    "\n",
    "def probe_model(x, y, model, label_names):\n",
    "    features_names = get_feature_names()\n",
    "    features_importance = model.feature_importances_\n",
    "    print(\"\\nFeature Importance\\n\")\n",
    "    print(\"=====================\\n\")\n",
    "    for i, features_name in enumerate(features_names):\n",
    "        print(\"%s = %0.3f\"%(features_name, features_importance[i]))\n",
    "        \n",
    "    #将决策树导出成图\n",
    "    tree.export_graphviz(model, out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(model, out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
