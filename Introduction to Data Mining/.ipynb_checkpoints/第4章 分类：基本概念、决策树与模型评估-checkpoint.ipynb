{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章 分类：基本概念、决策树与模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 预备知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义4.1 分类（classification） 分类任务就是通过学习得到一个目标函数（target function）$f$，把每个属性集 $x$ 映射到一个预先定义的类标号 $y$。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标函数也称分类模型（classification model）。分类模型可以用于以下目的。\n",
    "- **描述性建模** 分类模型可以作为解释性的工具，用于区分不同类中的对象。\n",
    "- **预测性建模** 分类模型还可以用于预测未知记录的类标号。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 解决分类问题的一般方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 决策树归纳（decision tree）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 决策树的工作原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树是一种由结点和有向边组成的层次结构。它包含三种结点：\n",
    "- 根节点（root node）,它没有入边，但有零条或多条出边。\n",
    "- 内部结点（internal node），恰有一条入边和两条或多条出边。\n",
    "- 叶节点（leaf node）或终结点（ternimal node），恰有一条入边，但没有出边。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 模型的过分拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类模型的误差大致分为两种：\n",
    "- **训练误差（training error）**：也称再带入误差（resubstitution error）或表现误差（apparent error），是在训练记录上误分类样本比例。\n",
    "- **泛化误差（generalization error）**：是模型在未知记录上的期望误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个好的分类模型必须具有低训练误差和低泛化误差，因为对训练数据拟合度过高的模型，其泛化误差可能比具有较高训练误差的模型高。这种情况就是所谓的**模型过分拟合**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 评估分类器的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 保持方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在保持（Holdout）方法中，将被标记的原始数据划分成两个不相交的集合，分别称为训练集和检验集。在训练数据集上归纳分类模型，在检验集上评估模型的性能。  \n",
    "保持方法有一些众所周知的局限性。\n",
    "- 第一，用于训练的被标记样本较少，因为要保留一部分记录用于检验，因此，建立的模型不如使用所有被标记样本建立的模型好。\n",
    "- 第二，模型可能高度依赖于训练集和检验集的构成。一方面，训练集越小，模型的方差越大，另一方面，如果训练集太大，根据用较小的检验集估计的准确率又不太可靠。这样的估计具有很宽的置信区间。\n",
    "- 最后，训练集和检验集不再是相互独立的。因为训练集和检验集来源于同一个数据集，在一个子集中超出比例的类在另一个子集就低于比例，反之亦然。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 随机二次抽样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以多次重复保持方法来改进对分类器性能的估计，这种方法称作随机二次抽样（random subsampling）。设 $acc_i$ 是第 $i$ 次迭代的模型准确率，总准确率是 $acc_{sub}=\\sum_{i=1}^k acc_i/k$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替代随机二次抽样的一种方法是交叉验证（cross-validation）。\n",
    "- 优点：使用尽可能多的训练记录，此外，检验集之间是互斥的，并且有效地覆盖了整个数据集；\n",
    "- 缺点：整个过程重复 $N$ 次，计算上开销很大，此外，因为每个检验集只有一个记录，性能估计度量的方差偏高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4 自助法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 比较分类器的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 估计准确度的置信区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
